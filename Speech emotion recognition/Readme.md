# Speech Emotion Recognition
This repository contains code for implementing Speech Emotion Recognition (SER) using Support Vector Machine (SVM) and Convolutional Neural Network (CNN) models. The project analyzes speech recordings to recognize emotions conveyed in the audio. 

## Datasets
The project utilizes several publicly available datasets to train and evaluate the models. These include: 

1. RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) - Emotions: Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised
2. SAVEE (Surrey Audio-Visual Expressed Emotion) - Emotions: Neutral, Happy, Sad, Angry, Fearful, Disgust
3. TESS (Toronto Emotional Speech Set) - Emotions: Neutral, Happy, Sad, Angry, Fearful, Disgust, Surprised
4. CREMA-D (Crowd-Sourced Emotional Multimodal Actors Dataset) - Emotions: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
  
## Getting Started 1.
**Downloading Datasets**:
- Please download the [datasets](https://drive.google.com/drive/folders/1IZmGdshttawFAsiiveT-VMsfD8ew3BTX?usp=sharing) from the provided link .

**Adjust File Paths**: - Before running the code, make sure to update the file paths and folders in the scripts to match the location where the datasets are stored on your system. 

## Usage 
The project includes the following files: - `speech-emotion-recognition.ipynb`: Implements the SVM and CNN models for speech emotion recognition. The project has merged the datasets with different emotions and generates output file of merged datasets and also for features extraction part the output of features file is generated. 
